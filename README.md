# JEPA-GFM: Joint Embedding Predictive Architecture for Geospatial Foundation Model  
*A GeoSpatial Foundation Model for Child-Centered Climate Risk Analysis*

## ğŸŒ Overview

This repository contains a **Proof of Concept (PoC)** implementation of **JEPA-GFM**, a geospatial foundation model based on the **Joint Embedding Predictive Architecture (JEPA)**. Unlike traditional computer vision models, JEPA-GFM is designed to handle **heterogeneous geospatial data** â€” including rasters, vectors, and tabular indicators â€” enabling seamless alignment across **different resolutions, formats, and spatial references**.

The model was developed as part of the **UN Hackathon Challenge 2: Solving the â€œGeo-Puzzleâ€**, aimed at addressing critical gaps in combining **multi-hazard data layers** with **child vulnerability factors**. By learning universal representations of geospatial inputs, JEPA-GFM enables **automated spatial reconciliation**, **scenario modeling**, and **real-time risk intelligence** that can be integrated into tools like **Giga Spatial** and **CCRI-DRM dashboards**.

## ğŸ“Š Example Training Results
![Example Training](predictions.png)
![Validation](training_curves.png)

## ğŸ” Key Objectives

- âœ… Solve the "Geo-Puzzle": Harmonize mismatched geospatial datasets (raster weather forecasts, vector infrastructure points, administrative-boundary child poverty rates)
- âœ… Build a reusable, self-supervised geospatial foundation model
- âœ… Enable plug-and-play decoders for downstream tasks (e.g., child exposure scoring, flood impact simulation)
- âœ… Integrate with Giga Spatial for ingestion and preprocessing
- âœ… Visualize results via CCRI-DRM-compatible dashboards

---

## ğŸ—ï¸ Architecture

JEPA-GFM adapts the **V-JEPA framework** from vision AI to the geospatial domain. It learns high-level representations of diverse spatial data without requiring labeled examples. The architecture includes:

1. **Context Encoder**: Encodes visible parts of geospatial data (weather maps, rasters, etc.)
2. **Target Encoder**: Maintains target representations using exponential moving average (EMA) updates
3. **Predictor Network**: Learns to predict masked region representations from context
4. **Decoder Modules**: Lightweight task-specific heads for:
   - Child exposure scoring
   - Flood-child overlay analysis
   - Uncertainty quantification
   - Scenario modeling

### Key Features

- **Multi-modal input support**: Raster, vector, and tabular data
- **Self-supervised learning**: No need for labeled training data
- **Latent space alignment**: Enables cross-format comparison
- **Modular design**: Easy integration with Giga Spatial and CCRI-DRM

---

## ğŸš€ Getting Started

### Installation

1. Clone this repository:
```bash
git clone <repository-url>
cd jepa-gfm
```

2. Create a virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

### Quick Start

#### 1. Generate Synthetic Data
```bash
python generate_data.py
```
Generates synthetic geospatial layers simulating hurricane paths, school locations, and child population density.

#### 2. Train the Model
```bash
python train.py
```
Trains JEPA-GFM encoder on synthetic geospatial data.

#### 3. Test the Model
```bash
python test.py
```
Validates modality fusion, resolution handling, and embedding quality.


## ğŸ¯ Demo Use Case: Hurricane Risk for Children

JEPA-GFM can be tested in a simulated scenario involving hurricane risk in **Saint Kitts and Nevis**:

1. **Input Layers**:
   - ECMWF hurricane forecast tracks (raster)
   - WorldPop child population data (raster)
   - School locations (point vector)
   - Administrative boundaries (polygon vector)

2. **Output**:
   - Estimated number of children exposed to storm surge
   - Heatmap of high-risk zones with uncertainty estimates

---

## ğŸ§ª Technical Highlights

| Feature | Description |
|--------|-------------|
| **Modalities Supported** | Raster (weather, elevation), Vector (points, polygons), Tabular (indicators) |
| **Self-Supervised Objective** | Latent-space prediction of masked regions |
| **Resolution Support** | Handles 128x128 to 512x512 pixel inputs |
| **Model Sizes** | Small (~25M), Base (~85M), Large (~300M) |
| **Training Strategy** | AdamW optimizer, EMA updates, patch masking |

---

## ğŸ“Š Evaluation & Limitations

### Current Capabilities
- âœ… Self-supervised pre-training on synthetic geospatial data
- âœ… Modular decoder architecture for task-specific inference
- âœ… Integration with Giga Spatial data format
- âœ… Proof-of-concept visualization in Geosight-compatible dashboards

### Known Limitations
- âš ï¸ Uses synthetic data due to time constraints (hackathon setting)
- âš ï¸ Limited to static spatial data (no time-series or temporal modeling yet)
- âš ï¸ Not yet deployed with real-time weather APIs (ECMWF/DWD)
- âš ï¸ Uncertainty quantification needs refinement

---

## ğŸš§ Future Work

- âœ… Integrate with live weather feeds (ECMWF/DWD)
- âœ… Add time-series modeling capabilities
- âœ… Improve uncertainty visualization for non-experts
- âœ… Expand decoder modules for other hazards (droughts, landslides)
- âœ… Optimize for deployment within UNICEF's operational workflows

---

## ğŸ“š References

1. **I-JEPA**: Assran, M., et al. *Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture.* CVPR 2023.
2. **V-JEPA**: Bardes, A., et al. *Revisiting Feature Prediction for Learning Visual Representations from Video.* arXiv 2023.
3. **Vision Transformer**: Dosovitskiy, A., et al. *An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.* ICLR 2021.
4. **Giga Spatial Documentation**: [https://unicef.github.io/giga-spatial/](https://unicef.github.io/giga-spatial/)
5. **CCRI-DRM Dashboard**: [Geosight Portal](https://geosight.org/)


## ğŸ“„ License

This project is released under the MIT License for educational and research purposes. Please ensure compliance with licensing requirements when integrating real geospatial datasets or deploying in production environments.

---

## ğŸ’¬ Contact

For questions or collaboration opportunities, please reach out to us:
- **Kerod Woldesenbet** â€“ kerod5858@gmail.com  
- **Abem Woldesenbet** â€“ abemkibatu101@gmail.com  

Or contact the challenge owner:
- **Yves Jaques** â€“ yjaques@unicef.org (UNICEF DAS Computational Analytics and Geospatial Intelligence Unit)

---

## ğŸ‰ Acknowledgments

Special thanks to:
- UNICEF and ITU for supporting initiatives like **Giga Spatial** and **CCRI-DRM**
- The UN Hackathon organizers for providing this opportunity
- The open-source community for foundational libraries like PyTorch, GeoPandas, and H3